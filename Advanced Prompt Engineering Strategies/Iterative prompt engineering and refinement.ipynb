{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21341d8c",
   "metadata": {},
   "source": [
    "# Setup API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5de91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import dotenv\n",
    "from dotenv import main\n",
    "\n",
    "\n",
    "main.load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b7acc8",
   "metadata": {},
   "source": [
    "# Create Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73754513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    # create a request to the chat completion endpoint\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [{\"role\":\"user\", \"content\":prompt}],\n",
    "        temperature = 0\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798940a5",
   "metadata": {},
   "source": [
    "# Iterative prompt engineering and refinement\n",
    "- No prompt can be perfect at the beginning\n",
    "- Prompt Engineering is an iterative process where we:\n",
    "       - Build a prompt\n",
    "       - Feed it to the model\n",
    "       - Observe and analyze the output\n",
    "       - Reiterate to make the prompt better\n",
    "\n",
    "### Refining prompts:\n",
    "#### Initial prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35aa173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Name | Grade\n",
      "------------ | -----\n",
      "John Doe     | 90\n",
      "Jane Smith   | 85\n",
      "Michael Lee  | 92\n",
      "Emily Johnson| 88\n",
      "David Brown  | 95\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Generate an Excel sheet containing five student names and their grades\"\"\"\n",
    "print(get_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df8bc7",
   "metadata": {},
   "source": [
    "#### Refined prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a551433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here is a table with five student names and their corresponding grades:\n",
      "\n",
      "| Student Name | Grade |\n",
      "|--------------|-------|\n",
      "| John         | 85    |\n",
      "| Emily        | 92    |\n",
      "| Michael      | 78    |\n",
      "| Sarah        | 88    |\n",
      "| David        | 95    |\n",
      "\n",
      "You can copy this table and paste it into Excel.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Generate a table that I can copy to excel, containing five student names and their grades.\"\n",
    "print(get_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f5dd89",
   "metadata": {},
   "source": [
    "# Tailor responses according to our needs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a211c3",
   "metadata": {},
   "source": [
    "### Example: analyzing a python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0855df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code defines a function called `calculate_rect_area` that takes in two parameters, `length` and `width`, and returns the sum of the two values.\n"
     ]
    }
   ],
   "source": [
    "code = '''\n",
    "def calculate_rect_area(length, width):\n",
    "    area = length + width\n",
    "    return area\n",
    "'''\n",
    "prompt = f\"\"\"\n",
    "    Analyze the code delimited by triple backticks with one sentence\n",
    "    ```{code}```\n",
    "\"\"\"\n",
    "print(get_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520af7b7",
   "metadata": {},
   "source": [
    "We modify prompts according to our demands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c6b0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description: This function calculates the area of a rectangle.\n",
      "language: Python\n",
      "input: The length and width of the rectangle.\n",
      "output: The calculated area of the rectangle.\n"
     ]
    }
   ],
   "source": [
    "# Suppose, you wanted more information, like which language the prompt was written in\n",
    "prompt = f\"\"\"\n",
    "    For the function delimited by triple backticks, provide in a \n",
    "    structured format the following:\n",
    "    - description: one sentence short description\n",
    "    - language: the programming language used\n",
    "    - input: the inputs to the function\n",
    "    - output: the output returned by the function\n",
    "    ```{code}```\n",
    "\"\"\"\n",
    "print(get_response(prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d55c57",
   "metadata": {},
   "source": [
    "# Few-shot prompt refinement\n",
    "- Weather description classification\n",
    "\n",
    "### Initial prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b87e533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowy\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    Clear skies and a gentle breeze. -> Sunny\n",
    "    Heavy rain and thunderstorms expected. -> Rainy\n",
    "    Fresh snowfall with freezing temperaturs. ->\n",
    "\n",
    "\"\"\"\n",
    "print(get_response(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caf75909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windy\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    Clear skies and a gentle breeze. -> Sunny\n",
    "    Heavy rain and thunderstorms expected. -> Rainy\n",
    "    Fresh snowfall with freezing temperaturs. ->\n",
    "    The wind of change brought a refreshing breeze to the company's\n",
    "    operations. ->\n",
    "\"\"\"\n",
    "print(get_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335eda2e",
   "metadata": {},
   "source": [
    "### Refined prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e6e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    Clear skies and a gentle breeze. -> Sunny\n",
    "    Heavy rain and thunderstorms expected. -> Rainy\n",
    "    The political climate in the country was stormy. -> Unknown\n",
    "    Fresh snowfall with freezing temperaturs. ->\n",
    "    The wind of change brought a refreshing breeze to the company's\n",
    "    operations. ->\n",
    "\"\"\"\n",
    "print(get_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7bf450",
   "metadata": {},
   "source": [
    "# Prompt refinement for various prompt types\n",
    "- Few-shot prompts: refine examples\n",
    "- Multi-step prompts: refine guiding steps\n",
    "- Chain-of-thought and self-consistency prompts: refine problem description\n",
    "\n",
    "#### Model might generate incorrect prompts due to lack of domain knowledge but we will learn how to deal with that in later chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d14423",
   "metadata": {},
   "source": [
    "# Exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea85675",
   "metadata": {},
   "source": [
    "# Iterative prompt engineering for standard prompts\n",
    "You are a developer using prompt engineering techniques for your various tasks, and you want to carefully select the right language model. You wrote an initial prompt to know what are the top ten pre-trained language models out there. Now, your goal is to refine this prompt to generate a table presenting information on each model's name, release year and its owning company.\n",
    "- Iteratively refine the prompt to get the desired outcome, a table having three columns for the top ten pre-trained language models listing the model name, release year, and owning company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a17bc9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. GPT-3 (Generative Pre-trained Transformer 3)\n",
      "2. BERT (Bidirectional Encoder Representations from Transformers)\n",
      "3. GPT-2 (Generative Pre-trained Transformer 2)\n",
      "4. RoBERTa (Robustly Optimized BERT Approach)\n",
      "5. XLNet (eXtreme Learning Network)\n",
      "6. ALBERT (A Lite BERT)\n",
      "7. T5 (Text-to-Text Transfer Transformer)\n",
      "8. ELECTRA (Efficiently Learning an Encoder that Classifies Token Replacements Accurately)\n",
      "9. DistilBERT (Distilled BERT)\n",
      "10. XLM-RoBERTa (Cross-lingual Language Model - RoBERTa)\n"
     ]
    }
   ],
   "source": [
    "# Refine the following prompt\n",
    "prompt = \"Give me the top 10 pre-trained language models\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4674e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model Name        | Release Year | Owning Company |\n",
      "|-------------------|--------------|----------------|\n",
      "| GPT-3             | 2020         | OpenAI         |\n",
      "| BERT              | 2018         | Google         |\n",
      "| GPT-2             | 2019         | OpenAI         |\n",
      "| RoBERTa           | 2019         | Facebook       |\n",
      "| XLNet             | 2019         | Google         |\n",
      "| ALBERT            | 2019         | Google         |\n",
      "| T5                | 2020         | Google         |\n",
      "| ELECTRA           | 2020         | Google         |\n",
      "| DistilBERT        | 2019         | Hugging Face   |\n",
      "| CTRL              | 2019         | OpenAI         |\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Generate a table having three columns of the top ten pre-trained language\n",
    "models listing the model name, release year and owning company\"\"\"\n",
    "print(get_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4012d",
   "metadata": {},
   "source": [
    "# Iterative prompt engineering for few-shot prompts\n",
    "You are currently working on a project at your content creation company. The project's objective is to develop a text classification model capable of accurately identifying and categorizing different emotions in text, such as happiness, sadness, and fear. In cases where the text does not contain any discernible emotion, you aim for the model to respond with \"no explicit emotion.\"\n",
    "\n",
    "You decided to use the provided few-shot prompt. However, you've noticed that \"Time flies like an arrow\" is being incorrectly classified as \"surprise.\" Your objective now is to refine the prompt so that the model correctly classifies this particular example as \"no explicit emotion.\"\n",
    "\n",
    "- Iteratively refine the prompt, by refining the examples, to get the output no explicit emotion for the \"Time flies like an arrow\" example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f7312d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no explicit emotion\n"
     ]
    }
   ],
   "source": [
    "# Refine the following prompt\n",
    "prompt = \"\"\"\n",
    "Receiving a promotion at work made me feel on top of the world -> Happiness\n",
    "The movie's ending left me with a heavy feeling in my chest -> Sadness\n",
    "Walking alone in the dark alley sent shivers down my spine -> Fear\n",
    "The sun rises on the west and sets on the east -> no explicit emotion\n",
    "Time flies like an arrow ->\n",
    "\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e19ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
